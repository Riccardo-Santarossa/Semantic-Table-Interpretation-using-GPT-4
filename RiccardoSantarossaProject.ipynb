{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71ef3907-1e8b-4a34-8781-4b990313d6c6",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6591b921-9d2a-480c-b104-6c0298d502f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: openai in /opt/conda/lib/python3.11/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.11/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from openai) (3.8.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.20->openai) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.20->openai) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.11/site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->openai) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install termcolor\n",
    "!pip install openai\n",
    "\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "import openai\n",
    "import requests\n",
    "import random\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "from termcolor import colored\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1351c0a6-db29-4f3c-8601-36fa4e5b59ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-05-15\"\n",
    "openai.api_base = \"\"\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5077d931-c96a-429e-bf03-3a2d94e3fa40",
   "metadata": {},
   "source": [
    "# Function Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f461b36-4f9c-4c9c-bccc-7085a93134ac",
   "metadata": {},
   "source": [
    "## OpenAI Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "445051cc-76e4-4d65-9f03-8ef3e76675e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(myPrompt):\n",
    "    my_engine=\"gpt4\"\n",
    "    response = openai.Completion.create(\n",
    "      engine = my_engine,\n",
    "      prompt = myPrompt,\n",
    "      temperature = 0.1,\n",
    "      max_tokens = 200,\n",
    "      frequency_penalty = 0.2,\n",
    "      presence_penalty = 0.2,\n",
    "      stop = None) \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7026b7e-2655-4fc2-b897-28103a322fee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LamAPI Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82c1663d-59e1-42b2-b824-8057e8b5391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = requests.Session()\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "url = \"https://lamapi.inside.disco.unimib.it/\"\n",
    "\n",
    "# Use LAMAPI to retrieve some entities from wikidata that could be suitable for the cell entity\n",
    "def lamapi_retrieval(cell):\n",
    "    cell = cell.strip()\n",
    "    params = {\n",
    "        'token': \"insideslab-lamapi-2022\",\n",
    "        'name': cell,\n",
    "        'kg': \"wikidata\",\n",
    "        'limit': 3\n",
    "        }\n",
    "    return s.get(\"https://lamapi.inside.disco.unimib.it/lookup/entity-retrieval\", headers=headers, params=params).json()[cell.lower()]\n",
    "\n",
    "# Use LAMAPI to identify the column type\n",
    "def lamapi_cta(column):\n",
    "    params = {\n",
    "        'token': \"insideslab-lamapi-2022\",\n",
    "        }\n",
    "    return s.post(url + \"sti/column-analysis\", headers=headers, params=params, json={\"json\":[column] }).json()\n",
    "\n",
    "#Use LAMAPI to retrieve the entity label from the entity id in wikidata\n",
    "def lamapi_entity_name(id):\n",
    "    params = {\n",
    "        'token': \"insideslab-lamapi-2022\",\n",
    "        'kg': \"wikidata\",\n",
    "        'lang':'en'\n",
    "        }\n",
    "    return s.post(url + \"entity/labels\", headers=headers, params=params, json={\"json\":[id]}).json()[\"wikidata\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5059085a-8c8c-4557-93fd-046a8eb70806",
   "metadata": {},
   "source": [
    "## Prompt Creation Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881f0e53-580b-4d94-91b6-360e40d49e8c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Prompt with pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a75afe8f-8dc4-4707-97b9-0ebdd36fd2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cea_prompt(cea_table, cea_pool_list):\n",
    "    cea_pool = \", \".join(map(str, cea_pool_list))\n",
    "    return \"\"\"\n",
    "    For each row r in table T:\n",
    "        For each field c in row r:\n",
    "            # Assume that the field contains an entity mention\n",
    "            entity_mention = r[c]\n",
    "            # Initialize a variable to track the best match\n",
    "            best_match = null\n",
    "            max_score = 0\n",
    "            # Search for matches in the entity pool P\n",
    "            For each entity p in pool P:\n",
    "                # Assume the function calculate_similarity_score returns a value representing the likelihood that the entity p is semantically appropriate for the entity_mention\n",
    "                score = calculate_similarity_score(entity_mention, p)\n",
    "                # Update the best match if the score is higher than the current maximum\n",
    "                If score > max_score:\n",
    "                    max_score = score\n",
    "                    best_match = p\n",
    "            # Assign the best match to the mention in the entity in the table\n",
    "            r[c] = best_match\n",
    "    \n",
    "    #Example usage:\n",
    "    table = \"\"\"+cea_table+\"\"\"\n",
    "    pool = \"\"\"+cea_pool+\"\"\"\n",
    "    Result = \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60cd1bc4-7887-4ce7-ac53-4855ad81174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a table and return a iterable dictionary of its columns \n",
    "def create_columns(table):\n",
    "    columns = {}\n",
    "    for row in table.split(\"\\n\"):\n",
    "        for index, cell in enumerate(row.split(\",\")):   \n",
    "            if index not in columns:\n",
    "                columns[index] = [cell]\n",
    "            else:\n",
    "                columns[index].append(cell)\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ae716a-d8db-4369-acb4-ac114a3bddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly choice 2 entities among the groundtruth entities in order to append them to the pool \n",
    "def random_choice(list):  \n",
    "    while True:\n",
    "        if len(list) < 2:\n",
    "            response_0 = lamapi_entity_name(list[0])\n",
    "            if response_0 != {}:\n",
    "                lab_entity_0 = response_0[list[0]][\"labels\"][\"en\"]\n",
    "                return list[0] + \" \" + lab_entity_0\n",
    "            else:\n",
    "                return 0\n",
    "        else:   \n",
    "            index_1, index_2 = random.sample(range(len(list)), 2)\n",
    "            response1 = lamapi_entity_name(list[index_1])\n",
    "            response2 = lamapi_entity_name(list[index_2])\n",
    "            if response1 != {}:\n",
    "                if response2 != {}:\n",
    "                    break\n",
    "    if response1[list[index_1]][\"labels\"].get(\"en\") is not None:\n",
    "        lab_entity_1 = response1[list[index_1]][\"labels\"][\"en\"]\n",
    "    else:\n",
    "        lab_entity_1 = \"generic\"\n",
    "    if response2[list[index_2]][\"labels\"].get(\"en\") is not None:\n",
    "        lab_entity_2 = response2[list[index_2]][\"labels\"][\"en\"]\n",
    "    else:\n",
    "        lab_entity_2 = \"generic\"\n",
    "    return list[index_1]+\" \"+lab_entity_1,list[index_2]+\" \"+lab_entity_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15c64220-0476-4d31-acd8-3088feb5b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pool of suitable entities for the table \n",
    "def create_pool(table, table_id):\n",
    "    columns = create_columns(table)\n",
    "    cells_list = []\n",
    "    pool = []\n",
    "    for key, value in columns.items():\n",
    "        if lamapi_cta(value)[\"0\"][\"tag\"] == \"NE\":\n",
    "            for cell in value:\n",
    "                cells_list.append(cell)\n",
    "            with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "                temp_entities = list(executor.map(lamapi_retrieval, cells_list))\n",
    "            for newlist in temp_entities:\n",
    "                for index in range(len(newlist)):\n",
    "                    id_ent = newlist[index][\"id\"]\n",
    "                    name_ent = newlist[index][\"name\"]\n",
    "                    pool.append(f\"{id_ent} {name_ent}\")\n",
    "                pool.extend(random_choice(list(gt_dict[table_id].values())))\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35b4e11-4ab1-4672-9d31-74a8bb7e3ec1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Prompt without pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ee345c2-9116-4565-8e90-d33f0366ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cea_prompt_no_pool(cea_table):\n",
    "    return \"\"\"\n",
    "    T = …\n",
    "    For each row r in table T:\n",
    "        For each field c in row r:\n",
    "            # Assume that the field contains an entity mention\n",
    "            entity_mention = r[c]\n",
    "    \n",
    "            # Initialize a variable to track the best match\n",
    "            best_match = null\n",
    "            max_score = 0\n",
    "    \n",
    "            # assume the get_entities_from_wikidata return entities from Wikidata that can be suitable for the entity_mention\n",
    "            candidate_entities = get_entities_from_wikidata(entity_mention)\n",
    "    \n",
    "            # Search for matches among candidate entities\n",
    "            For each wikidata_entity in candidate_entities:\n",
    "                # Calculate a similarity score between the mention in the table and the entity in Wikidata\n",
    "                score = calculate_similarity_score(entity_mention, wikidata_entity)\n",
    "    \n",
    "                # Update the best match if the score is higher than the current maximum\n",
    "                If score > max_score:\n",
    "                    max_score = score\n",
    "                    best_match = wikidata_entity\n",
    "    \n",
    "            # Assign the best match to the mention in the entity in the table\n",
    "            r[c] = best_match\n",
    "    \n",
    "    #Example usage:\n",
    "    table = \"\"\"+cea_table+\"\"\"\n",
    "    Result = \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d385dec-3a50-4c6b-9d20-4db0b22852db",
   "metadata": {},
   "source": [
    "## Prompt Execution Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f7d154a-448a-4858-a4f5-a603fe0e286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute each prompt from the prompt list\n",
    "def execute_prompt(prompt_dict):\n",
    "    list_exception = []\n",
    "    generation_dict = {}\n",
    "    i = 0\n",
    "    max_min = 120\n",
    "    start_time = time.time() \n",
    "    for key, value in tqdm_notebook(prompt_dict.items()):\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time > (max_min * 60): \n",
    "            break\n",
    "        generation_dict[key] = {}\n",
    "        time.sleep(0.3)\n",
    "        try:\n",
    "            generation_dict[key] = get_completion(value)[\"choices\"][0][\"text\"]\n",
    "        except Exception as e:\n",
    "            i += 1\n",
    "            list_exception.append(e)\n",
    "    print(str(i)+\" Prompt Execution Error\")\n",
    "    print(list_exception)\n",
    "    return generation_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9317606f-d591-493d-a90c-7ac62eee62ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Parsing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6ae1277-5272-4963-a203-6d9555791d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the row and column number with the entity associated\n",
    "def entity_extractor(table_annotation, table_id):\n",
    "    result = []\n",
    "    for row_num, row in enumerate(table_annotation, start=1):\n",
    "        column = row.split(',')\n",
    "        for column_num, entity in enumerate(column):\n",
    "            match = re.search(r'Q\\d+', entity)\n",
    "            if match:\n",
    "                wiki_entity = match.group()\n",
    "                result.append(f\"{table_id}, {row_num}, {column_num}, {wiki_entity}\")\n",
    "    if len(result) == 0:\n",
    "        result.append(f\"{table_id}, No Wikidata Entities Found\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1885b7b9-69e1-4b34-8a7f-c310a52cc50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the gpt response to keep only the table annotations\n",
    "def parser(raw_table_annotation):\n",
    "    if raw_table_annotation != {}:\n",
    "        rows = raw_table_annotation.split(\"\\n\")\n",
    "        result = []\n",
    "        found_empty_row = False    \n",
    "        for row in rows:\n",
    "            row = row.strip()\n",
    "            row = row.replace(\"\\t\", \",\")\n",
    "            if row == \"\":\n",
    "                found_empty_row = True\n",
    "            elif row == \"<|im_end|>\":\n",
    "                found_empty_row = True\n",
    "            elif found_empty_row:\n",
    "                break\n",
    "            elif row.endswith(\"<|im_end|>\"):\n",
    "                result.append(row.replace(\"<|im_end|>\", \"\"))\n",
    "            else:\n",
    "                result.append(row)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64425e2a-aed9-48b0-9d6c-f9b57220f009",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CSV Writing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66a2e0f4-9b99-41fd-bc9e-6b95bb6d8a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the annotation into a csv file\n",
    "def save_to_csv(file_name, list):\n",
    "    with open(file_name, mode='a', newline='') as file_csv:\n",
    "        writer = csv.writer(file_csv, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        for element in list:\n",
    "            writer.writerow([element])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e057faef-ee41-467e-abb9-f6afce7bb8ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# GT_Table Dictionary Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9e93872-a103-4d9f-b889-ac10630e3ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78da4d93c40f4b8385f52b6260481322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create the groundtruth dictionary \n",
    "cea_gt_path= [\n",
    "    \"./datasets/HardTablesR1/DataSets/HardTablesR1/Valid/gt/cea_gt.csv\",\n",
    "    \"./datasets/HardTablesR2/DataSets/HardTablesR2/Valid/gt/cea_gt.csv\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/GT/CEA/CEA_Round1_gt.csv\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/GT/CEA/CEA_Round2_gt.csv\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/GT/CEA/CEA_Round3_gt.csv\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/GT/CEA/CEA_Round4_gt.csv\",\n",
    "    \"./datasets/WikidataTables2023R1/DataSets/Valid/gt/cea_gt.csv\"\n",
    "]\n",
    "\n",
    "gt_dict = {}\n",
    "\n",
    "for cea_gt in tqdm_notebook(cea_gt_path):\n",
    "    with open(cea_gt) as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',')\n",
    "        next(spamreader)\n",
    "        for row in spamreader:\n",
    "            table_id = row[0]\n",
    "            row_id = row[1]\n",
    "            column_id = row[2]\n",
    "            entity = row[3]\n",
    "            if table_id not in gt_dict:\n",
    "                gt_dict[table_id] = {}\n",
    "                gt_dict[table_id][f\"{row_id}_{column_id}\"] = entity.replace(\"http://www.wikidata.org/entity/\", \"\")\n",
    "            else:\n",
    "                gt_dict[table_id][f\"{row_id}_{column_id}\"] = entity.replace(\"http://www.wikidata.org/entity/\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984a60df-1af9-4f10-9dc4-aeefbabf12b1",
   "metadata": {},
   "source": [
    "# Table Prompts Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0226ef-af1f-4d8c-ada7-bdf46f2633f8",
   "metadata": {},
   "source": [
    "## Prompt with pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11c30c80-b30e-4796-8817-1dd72d0c2f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ac77461eb44126a852ae51eecd73e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1ce27e2cb24967995a5976c630973f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m                    \u001b[38;5;66;03m# create the table by joining each string row\u001b[39;00m\n\u001b[1;32m     40\u001b[0m                    table_format \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_row\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 41\u001b[0m                 table_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[43mcreate_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_id\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     42\u001b[0m                 prompt_dict[table_id] \u001b[38;5;241m=\u001b[39m create_cea_prompt(table_format, table_pool)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(table_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m, in \u001b[0;36mcreate_pool\u001b[0;34m(table, table_id)\u001b[0m\n\u001b[1;32m     15\u001b[0m                 name_ent \u001b[38;5;241m=\u001b[39m newlist[index][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     16\u001b[0m                 pool\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mid_ent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname_ent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m             pool\u001b[38;5;241m.\u001b[39mextend(\u001b[43mrandom_choice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgt_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtable_id\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pool\n",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m, in \u001b[0;36mrandom_choice\u001b[0;34m(list)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:   \n\u001b[1;32m     12\u001b[0m     index_1, index_2 \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m)), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     response1 \u001b[38;5;241m=\u001b[39m \u001b[43mlamapi_entity_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mindex_1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     response2 \u001b[38;5;241m=\u001b[39m lamapi_entity_name(\u001b[38;5;28mlist\u001b[39m[index_2])\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response1 \u001b[38;5;241m!=\u001b[39m {}:\n",
      "Cell \u001b[0;32mIn[4], line 35\u001b[0m, in \u001b[0;36mlamapi_entity_name\u001b[0;34m(id)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlamapi_entity_name\u001b[39m(\u001b[38;5;28mid\u001b[39m):\n\u001b[1;32m     30\u001b[0m     params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minsideslab-lamapi-2022\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkg\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwikidata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlang\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     34\u001b[0m         }\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mentity/labels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwikidata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:637\u001b[0m, in \u001b[0;36mSession.post\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    627\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    807\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/ssl.py:1311\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1309\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1310\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#create the prompt with pool for each table\n",
    "tables_path= [\n",
    "    \"./datasets/HardTablesR1/DataSets/HardTablesR1/Valid/tables\",\n",
    "    \"./datasets/HardTablesR2/DataSets/HardTablesR2/Valid/tables\",\n",
    "    \"./datasets/WikidataTables2023R1/DataSets/Valid/tables\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/Round1/tables\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/Round2/tables\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/Round3/tables\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/Round4/tables\"\n",
    "]\n",
    "\n",
    "prompt_dict = {}\n",
    "max_min = 20\n",
    "\n",
    "# for each path\n",
    "for table_path in tqdm_notebook(tables_path):\n",
    "    # for each table in path\n",
    "    start_time = time.time() \n",
    "    for table in tqdm_notebook(os.listdir(table_path)):\n",
    "        # open CSV table at table_path/table\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time > (max_min * 60):  # Converti i minuti in secondi\n",
    "            print(f\"L'iterazione del percorso {table_path} ha superato {max_min} minuti.\")\n",
    "            break\n",
    "        else:\n",
    "            table_id = table.replace(\".csv\", \"\")\n",
    "            if table.endswith('.csv') and gt_dict.get(table_id):\n",
    "                prompt_dict[table_id]={}\n",
    "                with open(table_path + '/' + table) as csvfile:\n",
    "                    # create a csv.reader object to read the csv file\n",
    "                    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "                    # skip the first header row and point to the second one\n",
    "                    next(spamreader)\n",
    "                    table_format = \"\"\n",
    "                    # for each row in csv.reader object \n",
    "                    for row in spamreader:   \n",
    "                       # transforms the current row into a string by joining its elements with commas\n",
    "                       current_row = \",\".join(row)\n",
    "                       # create the table by joining each string row\n",
    "                       table_format += f\"{current_row}\\n\"\n",
    "                    table_pool = list(set(create_pool(table_format, table_id)))\n",
    "                    prompt_dict[table_id] = create_cea_prompt(table_format, table_pool)\n",
    "    print(table_path + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5f53c9-24b4-4e90-bcbd-103cc5aab7a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Prompt without pool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda7c31e-e51e-4c52-9773-03db52007182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the prompt without pool for each table\n",
    "tables_path= [\n",
    "    \"./datasets/HardTablesR1/DataSets/HardTablesR1/Valid/tables\",\n",
    "    \"./datasets/HardTablesR2/DataSets/HardTablesR2/Valid/tables\",\n",
    "    \"./datasets/WikidataTables2023R1/DataSets/Valid/tables\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/Round1/tables\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/Round2/tables\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/Round3/tables\",\n",
    "    \"./datasets/SemTab2020_Table_GT_Target/Round4/tables\"\n",
    "]\n",
    "\n",
    "prompt_dict_no_pool = {}\n",
    "max_min = 20\n",
    "\n",
    "# for each path\n",
    "for table_path in tqdm_notebook(tables_path):\n",
    "    # for each table in path\n",
    "    start_time = time.time() \n",
    "    for table in tqdm_notebook(os.listdir(table_path)):\n",
    "        # open CSV table at table_path/table\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time > (max_min * 60):  # Converti i minuti in secondi\n",
    "            print(f\"L'iterazione del percorso {table_path} ha superato {max_min} minuti.\")\n",
    "            break\n",
    "        else:\n",
    "            table_id = table.replace(\".csv\", \"\")\n",
    "            if table.endswith('.csv') and gt_dict.get(table_id):\n",
    "                prompt_dict_no_pool[table_id]={}\n",
    "                with open(table_path + '/' + table) as csvfile:\n",
    "                    # create a csv.reader object to read the csv file\n",
    "                    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "                    # skip the first header row and point to the second one\n",
    "                    next(spamreader)\n",
    "                    table_format = \"\"\n",
    "                    # for each row in csv.reader object \n",
    "                    for row in spamreader:   \n",
    "                       # transforms the current row into a string by joining its elements with commas\n",
    "                       current_row = \",\".join(row)\n",
    "                       # create the table by joining each string row\n",
    "                       table_format += f\"{current_row}\\n\"\n",
    "                    prompt_dict_no_pool[table_id] = create_cea_prompt_no_pool(table_format)\n",
    "    print(table_path + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062b32b4-c37c-4cba-8f2e-d0a83f8fcc4d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Prompt with Pool Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f46ad0-d4a9-451e-a764-c62d3719d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Annotate each table using GPT\n",
    "raw_annotations = execute_prompt(prompt_dict) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e4c202-0a2c-4b94-bf79-a47fca160d6e",
   "metadata": {},
   "source": [
    "## Parsing and Writing Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca5d58-6c31-4e2c-beff-d67192657594",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in tqdm_notebook(raw_annotations.items()):\n",
    "    if value != {}:\n",
    "        parsed_result = parser(value)\n",
    "        annotated_entities = entity_extractor(parsed_result, key)\n",
    "        save_to_csv(\"output.csv\", annotated_entities)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbf1028-c2c6-4d03-b953-677e8c696aae",
   "metadata": {},
   "source": [
    "# Prompt without Pool Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cac9276-2af7-4da6-a866-67b040c36a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Annotate each table using GPT\n",
    "raw_annotations_no_pool = execute_prompt(prompt_dict_no_pool) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1468b870-779c-426a-8fff-be80b412841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in tqdm_notebook(raw_annotations_no_pool.items()):\n",
    "    if value != {}:\n",
    "        parsed_result = parser(value)\n",
    "        annotated_entities = entity_extractor(parsed_result, key)\n",
    "        save_to_csv(\"output_no_pool.csv\", annotated_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e2d46a-77ce-48f4-9f75-f91d1de73ba8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Prompt with Pool Output Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800f9f56-4733-45ea-a127-80a7c7bd7a30",
   "metadata": {},
   "source": [
    "## Stats Analysys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c27788-4bee-401f-910d-6dc7953350ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CEA groundtruth path\n",
    "ann_out= \"./output.csv\"\n",
    "\n",
    "ann_dict = {}\n",
    "\n",
    "with open(ann_out) as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    next(spamreader)\n",
    "    for row in spamreader:\n",
    "        for element in row:\n",
    "            my_list = element.split(\",\")\n",
    "            table_id = my_list[0]\n",
    "            if(my_list[1] != \" No Wikidata Entities Found\"):\n",
    "                row_id = my_list[1].strip()\n",
    "                column_id = my_list[2].strip()\n",
    "                entity = my_list[3].strip()\n",
    "                if table_id not in ann_dict:\n",
    "                    ann_dict[table_id] = {}\n",
    "                    ann_dict[table_id][f\"{row_id}_{column_id}\"] = entity\n",
    "                else:\n",
    "                    ann_dict[table_id][f\"{row_id}_{column_id}\"] = entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72cb2fd-d9cb-46d1-9059-61249a75db9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_cell = 0\n",
    "wrong_cell = 0\n",
    "missing_cell = 0\n",
    "missing_table = 0\n",
    "entire_table = 0 \n",
    "n_cell = 0\n",
    "\n",
    "for key, value in gt_dict.items():\n",
    "    if key in ann_dict:\n",
    "        n_cell += len(gt_dict[key])\n",
    "        if gt_dict[key] == ann_dict[key]:  \n",
    "            entire_table += 1\n",
    "            right_cell += len(ann_dict[key])\n",
    "        else:\n",
    "            for gt_key, gt_value in gt_dict[key].items():\n",
    "                check = 0\n",
    "                try:\n",
    "                    num_cel_tab = len(gt_dict[key])\n",
    "                    if ann_dict[key][gt_key] == gt_value:\n",
    "                        right_cell += 1\n",
    "                        check += 1\n",
    "                    else:\n",
    "                        wrong_cell += 1                        \n",
    "                except:\n",
    "                    missing_cell += 1\n",
    "                if len(gt_dict[key]) == len(ann_dict[key]):\n",
    "                    if check == num_cel_tab:\n",
    "                        entire_table += 1\n",
    "\n",
    "\n",
    "print(colored(\"Output Analysis Prompt with Pool\",'red', attrs=['bold']))\n",
    "print(\"\")\n",
    "print(colored(\"Number of tables: \", 'red', attrs=['bold'])+ str(len(ann_dict)))  \n",
    "print(colored(\"Tabled correctly annotated: \", 'blue')+str(entire_table) + \" (\"+str(round(entire_table/len(ann_dict)*100, 2))+\"%)\")\n",
    "print(\"\")\n",
    "print(colored(\"Number of annotable cells: \", 'red', attrs=['bold'])+ str(n_cell))\n",
    "print(colored(\"Cells correctly annotated: \", 'blue')+str(right_cell)+\" (\"+str(round(right_cell/n_cell*100, 2))+\"%)\")\n",
    "print(colored(\"Cells misannotated: \", 'blue')+str(wrong_cell)+\" (\"+str(round(wrong_cell/n_cell*100, 2))+\"%)\")       \n",
    "print(colored(\"Missing cells' annotation: \", 'blue')+str(missing_cell)+\" (\"+str(round(missing_cell/n_cell*100, 2))+\"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aab91c-d9d5-449b-85c6-4e56513b40ec",
   "metadata": {},
   "source": [
    "## Table Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90334822-fa5a-4c38-ac9b-0eb55733ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"QI8FPOEX\"\n",
    "tab_right_cell = 0\n",
    "tab_wrong_cell = 0\n",
    "tab_missing_cell = 0\n",
    "print(colored(\"\\nGROUNDTRUTH ANNOTATIONS: \" + key , 'red', attrs=['bold']))\n",
    "if key in gt_dict:\n",
    "    value = gt_dict[key]\n",
    "    i = 0\n",
    "    temp_list = []\n",
    "    for col_row, value in gt_dict[key].items():\n",
    "        temp_list.append(col_row + \":\" + value)\n",
    "        if(len(temp_list) == 3):\n",
    "            print(temp_list)\n",
    "            temp_list = []\n",
    "        if temp_list:\n",
    "            print(temp_list)\n",
    "else:\n",
    "    print(colored(\"Do no exist gt table\", 'red'))\n",
    "print(colored(\"\\nGPT ANNOTATIONS: \", 'red', attrs=['bold']))\n",
    "if key in ann_dict:\n",
    "    for col_row, value in ann_dict[key].items():\n",
    "        temp_list.append(col_row + \":\" + value)\n",
    "        if(len(temp_list) == 3):\n",
    "            print(temp_list)\n",
    "            temp_list = []\n",
    "        try:\n",
    "            if gt_dict[key][col_row] == value:\n",
    "                tab_right_cell += 1\n",
    "            else:\n",
    "                tab_wrong_cell += 1                        \n",
    "        except:\n",
    "                tab_missing_cell += 1\n",
    "    if temp_list:\n",
    "        print(temp_list)\n",
    "    print(colored(\"\\nCorrect cells annotation: \", 'blue') +str(tab_right_cell))\n",
    "    print(colored(\"Incorrect cells annotation: \", 'blue') +str(tab_wrong_cell))\n",
    "    print(colored(\"Missing cells annotation: \", 'blue') +str(tab_missing_cell))\n",
    "else:\n",
    "    print(colored(\"Do no exist annotations for this table\", 'red'))\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d473e7-6e2c-4c78-924b-8abfe317504a",
   "metadata": {},
   "source": [
    "# Prompt without Pool Output Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8a66b2-34e7-4466-b1cf-c8ef3457b7cf",
   "metadata": {},
   "source": [
    "## Stats Analysys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4e88be-ee7d-4ed6-817c-ad3e18081f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CEA groundtruth path\n",
    "ann_out= \"./output_no_pool.csv\"\n",
    "\n",
    "ann_dict_no_pool = {}\n",
    "\n",
    "with open(ann_out) as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    next(spamreader)\n",
    "    for row in spamreader:\n",
    "        for element in row:\n",
    "            my_list = element.split(\",\")\n",
    "            table_id = my_list[0]\n",
    "            if(my_list[1] != \" No Wikidata Entities Found\"):\n",
    "                row_id = my_list[1].strip()\n",
    "                column_id = my_list[2].strip()\n",
    "                entity = my_list[3].strip()\n",
    "                if table_id not in ann_dict_no_pool:\n",
    "                    ann_dict_no_pool[table_id] = {}\n",
    "                    ann_dict_no_pool[table_id][f\"{row_id}_{column_id}\"] = entity\n",
    "                else:\n",
    "                    ann_dict_no_pool[table_id][f\"{row_id}_{column_id}\"] = entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ecd77-c8a1-485c-9382-9619d055040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_cell = 0\n",
    "wrong_cell = 0\n",
    "missing_cell = 0\n",
    "missing_table = 0\n",
    "entire_table = 0 \n",
    "n_cell = 0\n",
    "\n",
    "for key, value in gt_dict.items():\n",
    "    if key in ann_dict_no_pool:\n",
    "        n_cell += len(gt_dict[key])\n",
    "        if gt_dict[key] == ann_dict_no_pool[key]:  \n",
    "            entire_table += 1\n",
    "            right_cell += len(ann_dict_no_pool[key])\n",
    "        else:\n",
    "            for gt_key, gt_value in gt_dict[key].items():\n",
    "                check = 0\n",
    "                try:\n",
    "                    num_cel_tab = len(gt_dict[key])\n",
    "                    if ann_dict_no_pool[key][gt_key] == gt_value:\n",
    "                        right_cell += 1\n",
    "                        check += 1\n",
    "                    else:\n",
    "                        wrong_cell += 1                        \n",
    "                except:\n",
    "                    missing_cell += 1\n",
    "                if len(gt_dict[key]) == len(ann_dict_no_pool[key]):\n",
    "                    if check == num_cel_tab:\n",
    "                        entire_table += 1\n",
    "\n",
    "\n",
    "print(colored(\"Output Analysis Prompt without Pool\",'red', attrs=['bold']))\n",
    "print(\"\")\n",
    "\n",
    "print(colored(\"Number of tables: \", 'red', attrs=['bold'])+ str(len(ann_dict_no_pool)))  \n",
    "print(colored(\"Tabled correctly annotated: \", 'blue')+str(entire_table) + \" (\"+str(round(entire_table/len(ann_dict)*100, 2))+\"%)\")\n",
    "print(\"\")\n",
    "print(colored(\"Number of annotable cells: \", 'red', attrs=['bold'])+ str(n_cell))\n",
    "print(colored(\"Cells correctly annotated: \", 'blue')+str(right_cell)+\" (\"+str(round(right_cell/n_cell*100, 2))+\"%)\")\n",
    "print(colored(\"Cells misannotated: \", 'blue')+str(wrong_cell)+\" (\"+str(round(wrong_cell/n_cell*100, 2))+\"%)\")       \n",
    "print(colored(\"Missing cells' annotation: \", 'blue')+str(missing_cell)+\" (\"+str(round(missing_cell/n_cell*100, 2))+\"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16476031-0fc7-44f1-818c-c52a36ab48bf",
   "metadata": {},
   "source": [
    "## Table Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1e905e-94e3-4f87-bf96-a805554b75b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"ZK2S0Y91\"\n",
    "value = gt_dict[key]\n",
    "\n",
    "i = 0\n",
    "temp_list = []\n",
    "print(colored(\"\\nGROUNDTRUTH ANNOTATIONS: \" + key , 'red', attrs=['bold']))\n",
    "for col_row, value in gt_dict[key].items():\n",
    "    temp_list.append(col_row + \":\" + value)\n",
    "    if(len(temp_list) == 3):\n",
    "        print(temp_list)\n",
    "        temp_list = []\n",
    "if temp_list:\n",
    "    print(temp_list)\n",
    "print(colored(\"\\nGPT ANNOTATIONS: \", 'red', attrs=['bold']))\n",
    "if key in ann_dict_no_pool:\n",
    "    for col_row, value in ann_dict_no_pool[key].items():\n",
    "        temp_list.append(col_row + \":\" + value)\n",
    "        if(len(temp_list) == 3):\n",
    "            print(temp_list)\n",
    "            temp_list = []\n",
    "        try:\n",
    "            if gt_dict[key][col_row] == value:\n",
    "                tab_right_cell += 1\n",
    "            else:\n",
    "                tab_wrong_cell += 1                        \n",
    "        except:\n",
    "                tab_missing_cell += 1\n",
    "    if temp_list:\n",
    "        print(temp_list)\n",
    "    print(colored(\"\\nCorrect cells annotation: \", 'blue') +str(tab_right_cell))\n",
    "    print(colored(\"Incorrect cells annotation: \", 'blue') +str(tab_wrong_cell))\n",
    "    print(colored(\"Missing cells annotation: \", 'blue') +str(tab_missing_cell))\n",
    "else:\n",
    "    print(colored(\"Do no exist annotations for this table\", 'red'))\n",
    "       \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
